{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1My6L2kgUs4B"
      },
      "source": [
        "# Práctico 5\n",
        "1. Entrena y ajusta un árbol de decisión para el conjunto de datos moons siguiendo estos pasos:\n",
        "  - Usa make_moons(n_samples=10000, noise=0.4) para generar el conjunto de datos moons.\n",
        "  - Usa train_test_split() para dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba.\n",
        "  - Usa la búsqueda en cuadrícula con validación cruzada (con la ayuda de la clase GridSearchCV) para encontrar buenos valores de hiperparámetros para un DecisionTreeClassifier. Consejo: prueba varios valores para max_leaf_nodes.\n",
        "  - Entrena el modelo en el conjunto de entrenamiento completo utilizando estos hiperparámetros y mide su rendimiento en el conjunto de prueba. Deberías obtener una precisión aproximada del 85% al 87%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples = 10000, noise = 0.4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;max_leaf_nodes&#x27;: [2, 4, 8, 10, 20, 30, 40, 80, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;max_leaf_nodes&#x27;: [2, 4, 8, 10, 20, 30, 40, 80, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={'max_leaf_nodes': [2, 4, 8, 10, 20, 30, 40, 80, 100]})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "params = {'max_leaf_nodes': [2, 4, 8, 10, 20, 30, 40, 80, 100]}\n",
        "\n",
        "grid_search = GridSearchCV(model, params, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_leaf_nodes': 20}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8555"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = DecisionTreeClassifier(**grid_search.best_params_)\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calcular la precisión del modelo en el conjunto de prueba\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "accuracy\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Cargar el dataset de iris. Tomando solamente las variables de largo y ancho del pétalo, entrenar los distintos modelos de Clasificación que se vieron en clase y comparar los bordes generadas para cada una de las Clases.\n",
        "Modelos:\n",
        "  - Regresión Softmax\n",
        "  - Clasificador Estocástico (utilice 10000 iteraciones)\n",
        "  - SVM lineal\n",
        "  - SVM con kernel (pruebe diferentes kernels)\n",
        "  - Naive Bayes\n",
        "  - Decision Tree (utilice una profundidad máxima de 2)\n",
        "  - KNeighbors (varie el número de vecinos a 3)\n",
        "  \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Construya un modelo de ensamble de votación con los modelos anteriores.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Cree una muestra unidimensional con *y* dependiendo cuadraticamente de *x*, entrenar los distintos modelos de regresión que se vieron en clase y comparar las aproximaciones graficandolas. ¿En caso de querer extrapolar, que modelos no parecen ser una buena elección?\n",
        "Modelos:\n",
        "  - Regresión Lineal\n",
        "  - Regresión Polinomica\n",
        "  - Regresión Lineal Estocástica\n",
        "  - SVM lineal\n",
        "  - SVM con kernel\n",
        "  - Decision Tree\n",
        "  - KNeighbors\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Al igual que con los clasificadores, contruya un modelo de ensamble de votación, pero esta vez de regresión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvUslTw6VHbq"
      },
      "outputs": [],
      "source": [
        "### funcion para graficar \n",
        "from matplotlib.colors import ListedColormap\n",
        "def generate_iris_plot(clasifier):\n",
        "  x0, x1 = np.meshgrid(\n",
        "          np.linspace(0, 8, 500).reshape(-1, 1),\n",
        "          np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
        "      )\n",
        "\n",
        "  X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "\n",
        "  y_predict = clasifier.predict(X_new)\n",
        "\n",
        "  zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris virginica\")\n",
        "  plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris versicolor\")\n",
        "  plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris setosa\")\n",
        "\n",
        "  \n",
        "  custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "\n",
        "  plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "  plt.xlabel(\"Petal length\", fontsize=14)\n",
        "  plt.ylabel(\"Petal width\", fontsize=14)\n",
        "  plt.legend(loc=\"center left\", fontsize=14)\n",
        "  plt.axis([0, 8, 0, 3.5])\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlexqIr8X3Os"
      },
      "source": [
        "# Preguntas teoricas\n",
        "### Regresión\n",
        "1. ¿Qué algoritmo de entrenamiento de Regresión Lineal puedes usar si tienes un conjunto de entrenamiento con millones de características?\n",
        "2. Supongamos que las características en tu conjunto de entrenamiento tienen escalas muy diferentes. ¿Qué algoritmos podrían sufrir por esto y cómo? ¿Qué puedes hacer al respecto?\n",
        "3. ¿Puede el Descenso de Gradiente quedar atrapado en un mínimo local al entrenar un modelo de Regresión Logística?\n",
        "4. ¿Todos los algoritmos de Descenso de Gradiente conducen al mismo modelo, siempre y cuando los dejes correr el tiempo suficiente?\n",
        "5. Supongamos que usas Descenso de Gradiente por lotes y graficas el error de validación en cada época. Si notas que el error de validación consistentemente aumenta, ¿qué es lo que probablemente está sucediendo? ¿Cómo puedes solucionarlo?\n",
        "6. ¿Es una buena idea detener inmediatamente el Descenso de Gradiente por mini-lotes cuando el error de validación aumenta?\n",
        "7. ¿Qué algoritmo de Descenso de Gradiente (entre los que discutimos) llegará más rápido a la cercanía de la solución óptima? ¿Cuál convergerá realmente? ¿Cómo puedes hacer que los demás también converjan?\n",
        "8. Supongamos que estás utilizando Regresión Polinómica. Graficas las curvas de aprendizaje y notas que hay una gran brecha entre el error de entrenamiento y el error de validación. ¿Qué está sucediendo? ¿Cuáles son tres formas de solucionarlo?\n",
        "9. Supongamos que estás utilizando Regresión Ridge y notas que el error de entrenamiento y el error de validación son casi iguales y bastante altos. ¿Dirías que el modelo sufre de sesgo alto o de varianza alta? ¿Deberías aumentar el hiperparámetro de regularización α o reducirlo?\n",
        "10. ¿Por qué querrías usar:\n",
        "  - Regresión Ridge en lugar de Regresión Lineal simple (es decir, sin regularización)?\n",
        "  - Lasso en lugar de Regresión Ridge?\n",
        "  - Elastic Net en lugar de Lasso?\n",
        "11. Supongamos que quieres clasificar imágenes como exteriores/interiores y diurnas/nocturnas. ¿Deberías implementar dos clasificadores de Regresión Logística o uno de Regresión Softmax?\n",
        "### SVM\n",
        "1. ¿Cuál es la idea fundamental detrás de las Máquinas de Vectores de Soporte?\n",
        "2. ¿Qué es un vector de soporte?\n",
        "3. ¿Por qué es importante escalar las entradas al usar SVM?\n",
        "4. ¿Puede un clasificador SVM producir un puntaje de confianza al clasificar una instancia? ¿Y una probabilidad?\n",
        "5. ¿Deberías usar la forma primal o dual del problema SVM para entrenar un modelo en un conjunto de entrenamiento con millones de instancias y cientos de características?\n",
        "6. Digamos que has entrenado un clasificador SVM con un kernel RBF, pero parece subajustarse al conjunto de entrenamiento. ¿Deberías aumentar o disminuir γ (gamma)? ¿Y C?\n",
        "### Árboles de decisiones\n",
        "1. ¿Cuál es la profundidad aproximada de un árbol de decisión entrenado (sin restricciones) en un conjunto de entrenamiento con un millón de instancias?\n",
        "2. ¿La impureza de Gini de un nodo es generalmente menor o mayor que la de su padre? ¿Es generalmente menor/mayor o siempre menor/mayor?\n",
        "3. Si un árbol de decisión está sobreajustando el conjunto de entrenamiento, ¿es buena idea intentar disminuir max_depth?\n",
        "4. Si un árbol de decisión está subajustando el conjunto de entrenamiento, ¿es buena idea intentar escalar las características de entrada?\n",
        "5. Si tarda una hora en entrenar un árbol de decisión en un conjunto de entrenamiento que contiene 1 millón de instancias, ¿cuánto tiempo aproximado tomará entrenar otro árbol de decisión en un conjunto de entrenamiento que contiene 10 millones de instancias?\n",
        "6. Si su conjunto de entrenamiento contiene 100,000 instancias, ¿establecer presort=True acelerará el entrenamiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sofxvSWQdbWv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
